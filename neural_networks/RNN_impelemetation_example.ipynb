{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"tutorial_8_RNN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"K0WT6hSAPHZN"},"source":["### RNN Tutorial\n","\n","In this RNN tutorial we will code an RNN Cell, before training a RNN model on the Google Speech Commands dataset for keyword spotting systems: \n","\n","The Google Speech Commands dataset can be found here: [*Speech Commands*](https://www.tensorflow.org/tutorials/sequences/audio_recognition) v0.02 [1] dataset.\n","\n","[1] Warden, P. (2018). [Speech commands: A dataset for limited-vocabulary speech recognition](https://arxiv.org/abs/1804.03209). *arXiv preprint arXiv:1804.03209.*\n","\n","The tutorial is meant as a gentle introduction to Coursework 3 which will use the same dataset.\n","\n","### Tutorial structure\n","\n","There are four questions provided, please fill in the missing code for each question between the comments as signalled in the workbook. \n","\n","After these four questions there is additional code that will train your model on the Google Speech Commands dataset so you can see your model in practise.\n","\n","### Installing packages\n","\n","Please note, if you do not have librosa, you may need to download this."]},{"cell_type":"code","metadata":{"id":"0BU2JvzqPHZV","executionInfo":{"status":"ok","timestamp":1614350217687,"user_tz":0,"elapsed":8066,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["import math\n","import os\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset\n","import numpy as np\n","from scipy.io.wavfile import read\n","import librosa\n","from matplotlib import pyplot as plt\n","\n","cuda = True if torch.cuda.is_available() else False\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","\n","torch.manual_seed(42)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(42)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAGbGLtIPHZV"},"source":["### First we create a BasicRNNCell (Question 1):\n","\n","This should take input_data, and using the existing hidden state it should then return an updated hidden state."]},{"cell_type":"code","metadata":{"id":"wgj0_Lk4PHZW","executionInfo":{"status":"ok","timestamp":1614350219240,"user_tz":0,"elapsed":1546,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["class BasicRNNCell(nn.Module):\n","    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n","        super(BasicRNNCell, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.bias = bias\n","        self.nonlinearity = nonlinearity\n","        if self.nonlinearity not in [\"tanh\", \"relu\"]:\n","            raise ValueError(\"Invalid nonlinearity selected for RNN.\")\n","\n","        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n","        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n","\n","        self.reset_parameters()\n","        \n","\n","    def reset_parameters(self):\n","        std = 1.0 / math.sqrt(self.hidden_size)\n","        for w in self.parameters():\n","            w.data.uniform_(-std, std)\n","\n","            \n","    def forward(self, input_data, hx=None):\n","\n","        ''' \n","        input_data = current data\n","        hx = previous hidden state\n","        '''\n","        if hx is None:\n","            hx = input_data.new_zeros(input_data.size(0), self.hidden_size, requires_grad=False)\n","\n","        activation = getattr(nn.functional, self.nonlinearity)\n","        \n","        ########################################################################\n","        ## Q1) START OF YOUR CODE\n","        ########################################################################\n","        \n","        hy = self.h2h(hx) + self.x2h(input_data) + self.bias\n","        hy = activation(hy)\n","        \n","        ########################################################################\n","        ## END OF YOUR CODE\n","        ########################################################################\n","            \n","        return hy"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnR4xK4lPHZW"},"source":["### We will now incorporate our RNN memory cell into our RNN model below (Questions 2, 3 and 4):\n","\n","The following diagram below of a multi-layer RNN may be helpful:\n","https://gblobscdn.gitbook.com/assets%2F-LIA3amopGH9NC6Rf0mA%2F-M4bJ-IWAKzglR0XHFwU%2F-M4bJ3L0dfAgvfE4itLW%2Fmulti-layer-rnn.png?alt=media"]},{"cell_type":"code","metadata":{"id":"kPGZtiRVPHZW","executionInfo":{"status":"ok","timestamp":1614352497758,"user_tz":0,"elapsed":897,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["class RNNModel(nn.Module):\n","    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n","        super(RNNModel, self).__init__()\n","        self.mode = mode\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.bias = bias\n","        self.output_size = output_size\n","        \n","        self.rnn_cell_list = nn.ModuleList() # We append our BasicRNNCells to this list\n","        \n","        if mode == 'RNN_TANH':\n","            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n","                                                   self.hidden_size,\n","                                                   self.bias,\n","                                                   \"tanh\"))\n","            for l in range(1, self.num_layers):\n","                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n","                                                       self.hidden_size,\n","                                                       self.bias,\n","                                                       \"tanh\"))\n","          \n","        elif mode == 'RNN_RELU':\n","            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n","                                                   self.hidden_size,\n","                                                   self.bias,\n","                                                   \"relu\"))\n","            for l in range(1, self.num_layers):\n","                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n","                                                   self.hidden_size,\n","                                                   self.bias,\n","                                                   \"relu\"))\n","                \n","\n","            \n","        else:\n","            raise ValueError(\"Invalid RNN mode selected.\")\n","\n","        self.fc = nn.Linear(self.hidden_size, self.output_size)\n","        \n","    def forward(self, input_data, hx=None):\n","\n","        outs = []\n","        X = list(input_data.permute(1, 0, 2))\n","        h0 = [None] * self.num_layers if hx is None else list(hx)\n","        \n","        for j, l in enumerate(self.rnn_cell_list):\n","\n","            hx_minus_one = h0[j]\n","\n","            for i in range(input_data.shape[1]):\n","                hx = l(X[i], hx_minus_one)\n","                hx_minus_one = hx\n","                X[i] = hx\n","\n","                        \n","        outs = X\n","        out = outs[-1].squeeze()\n","        out = self.fc(out)\n","        return out\n","    "],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5V4yQquAPHZX"},"source":["Congratulations! You have completed the tutorial. Now try running the code below to see your model train"]},{"cell_type":"code","metadata":{"id":"GXLY-yynPHZY","executionInfo":{"status":"ok","timestamp":1614352499598,"user_tz":0,"elapsed":733,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["class SpeechCommandsDataset(Dataset):\n","    \"\"\"Google Speech Commands dataset.\"\"\"\n","\n","    def __init__(self, root_dir, split):\n","        \"\"\"\n","        Args:\n","            root_dir (string): Directory with all the data files.\n","            split    (string): In [\"train\", \"valid\", \"test\"].\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.split = split\n","\n","        self.number_of_classes = len(self.get_classes())\n","\n","        self.class_to_file = defaultdict(list)\n","\n","        self.valid_filenames = self.get_valid_filenames()\n","        self.test_filenames = self.get_test_filenames()\n","\n","        for c in self.get_classes():\n","            file_name_list = sorted(os.listdir(self.root_dir + \"data_speech_commands_v0.02/\" + c))\n","            for filename in file_name_list:\n","                if split == \"train\":\n","                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n","                        self.class_to_file[c].append(filename)\n","                elif split == \"valid\":\n","                    if filename in self.valid_filenames[c]:\n","                        self.class_to_file[c].append(filename)\n","                elif split == \"test\":\n","                    if filename in self.test_filenames[c]:\n","                        self.class_to_file[c].append(filename)\n","                else:\n","                    raise ValueError(\"Invalid split name.\")\n","\n","        self.filepath_list = list()\n","        self.label_list = list()\n","        for cc, c in enumerate(self.get_classes()):\n","            f_extension = sorted(list(self.class_to_file[c]))\n","            l_extension = [cc for i in f_extension]\n","            f_extension = [self.root_dir + \"data_speech_commands_v0.02/\" + c + \"/\" + filename for filename in f_extension]\n","            self.filepath_list.extend(f_extension)\n","            self.label_list.extend(l_extension)\n","        self.number_of_samples = len(self.filepath_list)\n","\n","    def __len__(self):\n","        return self.number_of_samples\n","\n","    def __getitem__(self, idx):\n","        sample = np.zeros((16000, ), dtype=np.float32)\n","\n","        sample_file = self.filepath_list[idx]\n","\n","        sample_from_file = read(sample_file)[1]\n","        sample[:sample_from_file.size] = sample_from_file\n","        sample = sample.reshape((16000, ))\n","        \n","        sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n","        \n","        label = self.label_list[idx]\n","\n","        return sample, label\n","\n","    def get_classes(self):\n","        return ['one', 'two', 'three']\n","\n","    def get_valid_filenames(self):\n","        class_names = self.get_classes()\n","\n","        class_to_filename = defaultdict(set)\n","        with open(self.root_dir + \"data_speech_commands_v0.02/validation_list.txt\", \"r\") as fp:\n","            for line in fp:\n","                clean_line = line.strip().split(\"/\")\n","\n","                if clean_line[0] in class_names:\n","                    class_to_filename[clean_line[0]].add(clean_line[1])\n","\n","        return class_to_filename\n","\n","    def get_test_filenames(self):\n","        class_names = self.get_classes()\n","\n","        class_to_filename = defaultdict(set)\n","        with open(self.root_dir + \"data_speech_commands_v0.02/testing_list.txt\", \"r\") as fp:\n","            for line in fp:\n","                clean_line = line.strip().split(\"/\")\n","\n","                if clean_line[0] in class_names:\n","                    class_to_filename[clean_line[0]].add(clean_line[1])\n","\n","        return class_to_filename"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSRsuzqRPHZZ","executionInfo":{"status":"ok","timestamp":1614352502668,"user_tz":0,"elapsed":705,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["## MAKE SURE THIS POINTS INSIDE THE DATASET FOLDER.\n","dataset_folder = \"/content/speech/\" # this should change depending on where you have stored the data files\n","\n","train_dataset = SpeechCommandsDataset(dataset_folder,\n","                                      \"train\")\n","valid_dataset = SpeechCommandsDataset(dataset_folder,\n","                                      \"valid\")\n","\n","test_dataset = SpeechCommandsDataset(dataset_folder,\n","                                     \"test\")\n","\n","## YOU MAY CHANGE THE BATCH SIZE.\n","batch_size = 57\n","\n","\n","num_epochs = 5\n","valid_every_n_steps = 20\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=False)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnJvFTSNyElJ","executionInfo":{"status":"ok","timestamp":1614350607843,"user_tz":0,"elapsed":1006,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}}},"source":["!rm -f /content/speech/data_speech_commands_v0.02/*"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"xF5Ys2cmPHZa","executionInfo":{"status":"ok","timestamp":1614353425230,"user_tz":0,"elapsed":921072,"user":{"displayName":"Yaniel Cabrera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnuKAiqQmMSKvIwoiQyk5G_g5QALh-semcxgjuQ6o=s64","userId":"16420725285670537399"}},"outputId":"3427ce3d-8804-4dad-b13d-292f88082d87"},"source":["# Parts of experiment code based on: https://github.com/emadRad/lstm-gru-pytorch\n","import time\n","seq_dim, input_dim = train_dataset[0][0].shape\n","output_dim = 3\n","\n","hidden_dim = 32\n","layer_dim = 4\n","bias = True\n","\n","model = RNNModel(\"RNN_TANH\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n","\n","if torch.cuda.is_available():\n","    model.cuda()\n","    \n","criterion = nn.CrossEntropyLoss()\n","\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","loss_list = []\n","it = 0\n","max_v_accuracy = 0\n","reported_t_accuracy = 0\n","max_t_accuracy = 0\n","\n","start = time.time()\n","for epoch in range(num_epochs):\n","    for i, (audio, labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n","            labels = Variable(labels.cuda())\n","        else:\n","            audio = Variable(audio.view(-1, seq_dim, input_dim))\n","            labels = Variable(labels)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(audio)\n","\n","        loss = criterion(outputs, labels)\n","\n","        if torch.cuda.is_available():\n","            loss.cuda()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        loss_list.append(loss.item())\n","        it += 1\n","\n","        if it % valid_every_n_steps == 0:\n","            correct = 0\n","            total = 0\n","            for audio, labels in valid_loader:\n","                if torch.cuda.is_available():\n","                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n","                else:\n","                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n","\n","                outputs = model(audio)\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","\n","                total += labels.size(0)\n","\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum()\n","                else:\n","                    correct += (predicted == labels).sum()\n","\n","            v_accuracy = 100 * correct // total\n","            \n","            is_best = False\n","            if v_accuracy >= max_v_accuracy:\n","                max_v_accuracy = v_accuracy\n","                is_best = True\n","\n","            if is_best:\n","                for audio, labels in test_loader:\n","                    if torch.cuda.is_available():\n","                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n","                    else:\n","                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n","\n","                    outputs = model(audio)\n","\n","                    _, predicted = torch.max(outputs.data, 1)\n","\n","                    total += labels.size(0)\n","\n","                    if torch.cuda.is_available():\n","                        correct += (predicted.cpu() == labels.cpu()).sum()\n","                    else:\n","                        correct += (predicted == labels).sum()\n","\n","                t_accuracy = 100 * correct // total\n","                reported_t_accuracy = t_accuracy\n","\n","            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n","\n","end = time.time()\n","print(\"time cost: {}\".format(end-start))"],"execution_count":75,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Iteration: <built-in function iter>. Loss: 1.0911846160888672. V-Accuracy: 33  T-Accuracy: 33\n","Iteration: <built-in function iter>. Loss: 1.098112940788269. V-Accuracy: 31  T-Accuracy: 33\n","Iteration: <built-in function iter>. Loss: 1.0942038297653198. V-Accuracy: 33  T-Accuracy: 32\n","Iteration: <built-in function iter>. Loss: 1.105771541595459. V-Accuracy: 33  T-Accuracy: 32\n","Iteration: <built-in function iter>. Loss: 1.0889177322387695. V-Accuracy: 33  T-Accuracy: 33\n","Iteration: <built-in function iter>. Loss: 1.0900583267211914. V-Accuracy: 32  T-Accuracy: 33\n","Iteration: <built-in function iter>. Loss: 1.0984172821044922. V-Accuracy: 33  T-Accuracy: 32\n","Iteration: <built-in function iter>. Loss: 1.0849072933197021. V-Accuracy: 32  T-Accuracy: 32\n","Iteration: <built-in function iter>. Loss: 1.0929137468338013. V-Accuracy: 38  T-Accuracy: 37\n","Iteration: <built-in function iter>. Loss: 1.077701449394226. V-Accuracy: 47  T-Accuracy: 46\n","Iteration: <built-in function iter>. Loss: 1.0406925678253174. V-Accuracy: 49  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0874390602111816. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.1119003295898438. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0948188304901123. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.1038554906845093. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0957907438278198. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.09676194190979. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.100498914718628. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0970170497894287. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.09298837184906. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.097483515739441. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0899471044540405. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.092233419418335. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.1030147075653076. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.1139287948608398. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0858443975448608. V-Accuracy: 33  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0978243350982666. V-Accuracy: 36  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0997424125671387. V-Accuracy: 37  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.103296160697937. V-Accuracy: 32  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0945152044296265. V-Accuracy: 36  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.111680269241333. V-Accuracy: 40  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0553832054138184. V-Accuracy: 40  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.2256054878234863. V-Accuracy: 34  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 1.0777453184127808. V-Accuracy: 42  T-Accuracy: 48\n","Iteration: <built-in function iter>. Loss: 0.9129509925842285. V-Accuracy: 53  T-Accuracy: 51\n","Iteration: <built-in function iter>. Loss: 0.8262239694595337. V-Accuracy: 49  T-Accuracy: 51\n","Iteration: <built-in function iter>. Loss: 1.0051859617233276. V-Accuracy: 53  T-Accuracy: 51\n","Iteration: <built-in function iter>. Loss: 1.168287754058838. V-Accuracy: 33  T-Accuracy: 51\n","Iteration: <built-in function iter>. Loss: 1.0600855350494385. V-Accuracy: 51  T-Accuracy: 51\n","Iteration: <built-in function iter>. Loss: 1.0263506174087524. V-Accuracy: 42  T-Accuracy: 51\n","time cost: 920.1349668502808\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1VsJrA_sPHZa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1DI5uZdPHZb"},"source":[""],"execution_count":null,"outputs":[]}]}